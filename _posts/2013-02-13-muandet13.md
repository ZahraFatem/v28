---
pdf: http://proceedings.mlr.press/v28/muandet13.pdf
supplementary: Supplementary:muandet13-supp.pdf
title: Domain Generalization via Invariant Feature Representation
number: 0
section: cycle-1
abstract: 'This paper investigates domain generalization: How to take knowledge acquired
  from an arbitrary number of related domains and apply it to previously unseen domains?
  We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization
  algorithm that learns an invariant transformation by minimizing the dissimilarity
  across domains, whilst preserving the functional relationship between input and
  output variables. A learning-theoretic analysis shows that reducing dissimilarity
  improves the expected generalization ability of classifiers on new domains, motivating
  the proposed algorithm. Experimental results on synthetic and real-world datasets
  demonstrate that DICA successfully learns invariant features and improves classifier
  performance in practice.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: muandet13
month: 0
tex_title: Domain Generalization via Invariant Feature Representation
firstpage: 10
lastpage: 18
page: 10-18
cycles: false
author:
- given: Krikamol
  family: Muandet
- given: David
  family: Balduzzi
- given: Bernhard
  family: Sch√∂lkopf
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
