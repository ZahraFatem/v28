---
pdf: http://proceedings.mlr.press/v28/zhang13c.pdf
supplementary: Supplementary:zhang13c-supp.pdf
number: '3'
section: cycle-3
title: Online Kernel Learning with a Near Optimal Sparsity Bound
abstract: In this work, we focus on Online Sparse Kernel Learning that aims to online
  learn a kernel classifier with a bounded number of support vectors. Although many
  online learning algorithms have been proposed to learn a sparse kernel classifier,
  most of them fail to bound the number of support vectors used by the final solution
  which is the average of the intermediate kernel classifiers generated by online
  algorithms. The key idea of the proposed algorithm is to measure the difficulty
  in correctly classifying a training example by the derivative of a smooth loss function,
  and give a more chance to a difficult example to be a support vector than an easy
  one via a sampling scheme. Our analysis shows that when the loss function is smooth,
  the proposed algorithm yields similar performance guarantee as the standard online
  learning algorithm but with a near optimal number of support vectors (up to a poly(lnT)
  factor). Our empirical study shows promising performance of the proposed algorithm
  compared to the state-of-the-art algorithms for online sparse kernel learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhang13c
month: 0
tex_title: Online Kernel Learning with a Near Optimal Sparsity Bound
firstpage: 621
lastpage: 629
page: 621-629
sections: 
author:
- given: Lijun
  family: Zhang
- given: Jinfeng
  family: Yi
- given: Rong
  family: Jin
- given: Ming
  family: Lin
- given: Xiaofei
  family: He
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
