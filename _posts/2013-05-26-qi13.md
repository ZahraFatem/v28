---
pdf: http://proceedings.mlr.press/v28/qi13.pdf
supplementary: http://proceedings.mlr.press/v28/qi13-supp.pdf
number: 3
section: cycle-3
title: Message passing with l1 penalized KL minimization
abstract: Bayesian inference is often hampered by large computational expense.  As
  a generalization of belief propagation (BP), expectation propagation (EP) approximates
  exact Bayesian computation with efficient message passing updates. However, when
  an approximation family used by EP is far from exact posterior distributions, message
  passing may lead to poor approximation quality and suffer from divergence. To address
  this issue, we propose an  approximate inference method, relaxed expectation propagation(REP),
  based on a new divergence with a l1 penalty. Minimizing this penalized divergence
  adaptively relaxes EP’s moment matching requirement for message passing. We apply
  REP to Gaussian process classification and experimental results demonstrate significant
  improvement of REP over EP and alpha-divergence based power EP – in terms of algorithmic
  stability, estimation accuracy, and predictive performance. Furthermore, we develop
  relaxed belief propagation(RBP), a special case of REP, to conduct inference on
  discrete Markov random fields (MRFs). Our results show improved estimation accuracy
  of RBP over BP and fractional BP when interactions between MRF nodes are strong.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: qi13
month: 0
tex_title: Message passing with l1 penalized KL minimization
firstpage: 262
lastpage: 270
page: 262-270
order: 262
cycles: false
author:
- given: Yuan
  family: Qi
- given: Yandong
  family: Guo
date: 2013-05-26
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 5
  - 26
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
