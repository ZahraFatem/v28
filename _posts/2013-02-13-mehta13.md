---
pdf: http://proceedings.mlr.press/v28/mehta13.pdf
supplementary: Supplementary:mehta13-supp.pdf
title: Sparsity-Based Generalization Bounds for Predictive Sparse Coding
number: '1'
section: cycle-1
abstract: The goal of predictive sparse coding is to learn a representation of examples
  as sparse linear combinations of elements from a dictionary, such that a learned
  hypothesis linear in the new representation performs well on a predictive task.
  Predictive sparse coding has demonstrated impressive performance on a variety of
  supervised tasks, but its generalization properties have not been studied. We establish
  the first generalization error bounds for predictive sparse coding, in the overcomplete
  setting, where the number of features k exceeds the original dimensionality d. The
  learning bound decays as (sqrt(d k/m)) with respect to d, k, and the size m of the
  training sample. It depends intimately on stability properties of the learned sparse
  encoder, as measured on the training sample. Consequently, we also present a fundamental
  stability result for the LASSO, a result that characterizes the stability of the
  sparse codes with respect to dictionary perturbations.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mehta13
month: 0
firstpage: 36
lastpage: 44
page: 36-44
sections: 
author:
- given: Nishant
  family: Mehta
- given: Alexander
  family: Gray
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
