---
pdf: http://proceedings.mlr.press/v28/karbasi13.pdf
supplementary: Supplementary:karbasi13-supp.pdf
title: Iterative Learning and Denoising in Convolutional Neural Associative Memories
number: '1'
section: cycle-1
abstract: The task of a neural associative memory is to retrieve a set of previously
  memorized patterns from their noisy versions by using a network of neurons. Hence,
  an ideal network should be able to 1) gradually learn a set of patterns, 2) retrieve
  the correct pattern from noisy queries and 3) maximize the number of memorized patterns
  while maintaining the reliability in responding to queries. We show that by considering
  the inherent redundancy in the memorized patterns, one can obtain all the mentioned
  properties at once. This is in sharp contrast with the previous work that could
  only improve one or two aspects at the expense of the third. More specifically,
  we devise an iterative algorithm that learns the redundancy among the patterns.
  The resulting network has a  retrieval capacity that is exponential in the size
  of the network. Lastly, by considering the local structures of the network, the
  asymptotic error correction performance  can be made linear in the size of the network.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: karbasi13
month: 0
tex_title: Iterative Learning and Denoising in Convolutional Neural Associative Memories
firstpage: 445
lastpage: 453
page: 445-453
sections: 
author:
- given: Amin
  family: Karbasi
- given: Amir Hesam
  family: Salavati
- given: Amin
  family: Shokrollahi
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
