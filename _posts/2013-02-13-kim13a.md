---
pdf: http://proceedings.mlr.press/v28/kim13a/kim13a.pdf
number: '3'
section: cycle-3
title: Manifold Preserving Hierarchical Topic Models for Quantization and Approximation
abstract: We present two complementary topic models to address the analysis of mixture
  data lying on manifolds. First, we propose a quantization method with an additional
  mid-layer latent variable, which selects only data points that best preserve the
  manifold structure of the input data. In order to address the case of modeling all
  the in-between parts of that manifold using this reduced representation of the input,
  we introduce a new model that provides a manifold-aware interpolation method. We
  demonstrate the advantages of these models with experiments on the hand-written
  digit recognition and the speech source separation tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kim13a
month: 0
firstpage: 1373
lastpage: 1381
page: 1373-1381
sections: 
author:
- given: Minje
  family: Kim
- given: Paris
  family: Smaragdis
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
