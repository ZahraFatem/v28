---
pdf: http://proceedings.mlr.press/v28/wong13/wong13.pdf
title: Adaptive Sparsity in {G}aussian Graphical Models
number: '1'
section: cycle-1
abstract: An effective approach to structure learning and parameter estimation for
  Gaussian graphical models is to impose a sparsity prior, such as a Laplace prior,
  on the entries of the precision matrix. Such an approach involves a hyperparameter
  that must be tuned to control the amount of sparsity. In this paper, we introduce
  a parameter-free method for estimating a precision matrix with sparsity that adapts
  to the data automatically. We achieve this by formulating a hierarchical Bayesian
  model of the precision matrix with a non-informative Jeffreysâ€™ hyperprior. We also
  naturally enforce the symmetry and positive-definiteness constraints on the precision
  matrix by parameterizing it with the Cholesky decomposition. Experiments on simulated
  and real (cell signaling) data demonstrate that the proposed approach not only automatically
  adapts the sparsity of the model, but it also results in improved estimates of the
  precision matrix compared to the Laplace prior model with sparsity parameter chosen
  by cross-validation.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wong13
month: 0
firstpage: 311
lastpage: 319
page: 311-319
sections: 
author:
- given: Eleanor
  family: Wong
- given: Suyash
  family: Awate
- given: P. Thomas
  family: Fletcher
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
