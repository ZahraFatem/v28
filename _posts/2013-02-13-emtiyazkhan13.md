---
pdf: http://proceedings.mlr.press/v28/emtiyazkhan13.pdf
number: '3'
section: cycle-3
title: Fast Dual Variational Inference for Non-Conjugate Latent Gaussian Models
abstract: 'Latent Gaussian models (LGMs) are widely used in statistics and machine
  learning.  Bayesian inference in non-conjugate LGM is difficult due to intractable
  integrals involving the Gaussian prior and non-conjugate likelihoods.  Algorithms
  based on Variational Gaussian (VG) approximations are widely employed since they
  strike a favorable balance between accuracy, generality, speed, and ease of use.  However,
  the structure of optimization problems associated with them    remains poorly understood,
  and standard solvers take too long to converge.  In this paper, we derive a novel
  dual variational inference approach, which exploits the convexity property of the
  VG approximations.   The implications of our approach is that we obtain an algorithm
  that solves a convex optimization problem, reduces the number of variational parameters,
  and converges much faster than previous methods.  Using real world data, we demonstrate
  these advantages on a variety of LGMs including Gaussian process classification
  and latent Gaussian Markov random fields.    '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: emtiyazkhan13
month: 0
firstpage: 951
lastpage: 959
page: 951-959
sections: 
author:
- given: Mohammad
  family: Emtiyaz Khan
- given: Aleksandr
  family: Aravkin
- given: Michael
  family: Friedlander
- given: Matthias
  family: Seeger
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
