---
pdf: http://proceedings.mlr.press/v28/bengio13.pdf
title: Better Mixing via Deep Representations
number: '1'
section: cycle-1
abstract: 'It has been hypothesized, and supported with experimental evidence, that
  deeper representations, when well trained, tend to do a better job at disentangling
  the underlying factors of variation.  We study the following related conjecture:
  better representations, in the sense of better disentangling, can be exploited to
  produce Markov chains that mix faster between modes. Consequently, mixing between
  modes would be more efficient at higher levels of representation.  To better understand
  this, we propose a secondary conjecture: the higher-level samples fill more uniformly
  the space they occupy and the high-density manifolds tend to unfold when represented
  at higher levels.  The paper discusses these hypotheses and tests them experimentally
  through visualization and measurements of mixing between modes and interpolating
  between samples.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: bengio13
month: 0
firstpage: 552
lastpage: 560
page: 552-560
sections: 
author:
- given: Yoshua
  family: Bengio
- given: Gregoire
  family: Mesnil
- given: Yann
  family: Dauphin
- given: Salah
  family: Rifai
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
