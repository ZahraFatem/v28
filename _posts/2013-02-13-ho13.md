---
pdf: http://proceedings.mlr.press/v28/ho13.pdf
title: Adaptive Task Assignment for Crowdsourced Classification
number: '1'
section: cycle-1
abstract: Crowdsourcing markets have gained popularity as a tool for inexpensively
  collecting data from diverse populations of workers. Classification tasks, in which
  workers provide labels (such as “offensive” or “not offensive”) for instances (such
  as websites), are among the most common tasks posted, but due to a mix of human
  error and the overwhelming prevalence of spam, the labels collected are often noisy.
  This problem is typically addressed by collecting labels for each instance from
  multiple workers and combining them in a clever way. However, the question of how
  to choose which tasks to assign to each worker is often overlooked. We investigate
  the problem of task assignment and label inference for heterogeneous classification
  tasks. By applying online primal-dual techniques, we derive a provably near-optimal
  adaptive assignment algorithm. We show that adaptively assigning workers to tasks
  can lead to more accurate predictions at a lower cost when the available workers
  are diverse.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ho13
month: 0
firstpage: 534
lastpage: 542
page: 534-542
sections: 
author:
- given: Chien-Ju
  family: Ho
- given: Shahin
  family: Jabbari
- given: Jennifer Wortman
  family: Vaughan
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
