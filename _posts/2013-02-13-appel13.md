---
pdf: http://proceedings.mlr.press/v28/appel13/appel13.pdf
supplementary: Supplementary:appel13-supp.pdf
number: '3'
section: cycle-3
title: Quickly Boosting Decision Trees -- Pruning Underachieving Features Early
abstract: Boosted decision trees are one of the most popular and successful learning
  techniques used today.  While exhibiting fast speeds at test time, relatively slow
  training makes them impractical for applications with real-time learning requirements.
  We propose a principled approach to overcome this drawback. We prove a bound on
  the error of a decision stump given its preliminary error on a subset of the training
  data; the bound may be used to prune unpromising features early on in the training
  process. We propose a fast training algorithm that exploits this bound, yielding
  speedups of an order of magnitude at no cost in the final performance of the classifier.
  Our method is not a new variant of Boosting; rather, it may be used in conjunction
  with existing Boosting algorithms and other sampling heuristics to achieve even
  greater speedups.
layout: inproceedings
id: appel13
month: 0
firstpage: 594
lastpage: 602
page: 594-602
sections: 
author:
- given: Ron
  family: Appel
- given: Thomas
  family: Fuchs
- given: Piotr
  family: Dollar
- given: Pietro
  family: Perona
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
