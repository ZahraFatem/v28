---
pdf: http://proceedings.mlr.press/v28/london13.pdf
supplementary: Supplementary:london13-supp.pdf
number: '3'
section: cycle-3
title: 'Collective Stability in Structured Prediction: Generalization from One Example'
abstract: Structured predictors enable joint inference over multiple interdependent
  output variables. These models are often trained on a small number of examples with
  large internal structure. Existing distribution-free generalization bounds do not
  guarantee generalization in this setting, though this contradicts a large body of
  empirical evidence from computer vision, natural language processing, social networks
  and other fields. In this paper, we identify a set of natural conditions – weak
  dependence, hypothesis complexity and a new measure, collective stability – that
  are sufficient for generalization from even a single example, without imposing an
  explicit generative model of the data. We then demonstrate that the complexity and
  stability conditions are satisfied by a broad class of models, including marginal
  inference in templated graphical models. We thus obtain uniform convergence rates
  that can decrease significantly faster than previous bounds, particularly when each
  structured example is sufficiently large and the number of training examples is
  constant, even one.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: london13
month: 0
firstpage: 828
lastpage: 836
page: 828-836
sections: 
author:
- given: Ben
  family: London
- given: Bert
  family: Huang
- given: Ben
  family: Taskar
- given: Lise
  family: Getoor
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
