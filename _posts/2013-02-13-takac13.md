---
pdf: http://proceedings.mlr.press/v28/takac13.pdf
supplementary: Supplementary:takac13-supp.pdf
number: '3'
section: cycle-3
title: Mini-Batch Primal and Dual Methods for SVMs
abstract: We address the issue of using mini-batches in stochastic  optimization of
  SVMs. We show that the same quantity, the  spectral norm of the data, controls the
  parallelization  speedup obtained for both primal stochastic subgradient descent(SGD)
  and stochastic dual coordinate ascent (SCDA) methods and use it to derive novel
  variants of mini-batched SDCA. Our guarantees for both methods are expressed in
  terms of the original nonsmooth primal problem based on the hinge-loss.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: takac13
month: 0
tex_title: Mini-Batch Primal and Dual Methods for SVMs
firstpage: 1022
lastpage: 1030
page: 1022-1030
sections: 
author:
- given: Martin
  family: Takac
- given: Avleen
  family: Bijral
- given: Peter
  family: Richtarik
- given: Nati
  family: Srebro
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
