---
pdf: http://proceedings.mlr.press/v28/tamar13.pdf
supplementary: Supplementary:tamar13-supp.pdf
number: 3
section: cycle-3
title: Temporal Difference Methods for the Variance of the Reward To Go
abstract: In this paper we extend temporal difference policy evaluation algorithms
  to performance criteria that include the variance of the cumulative reward. Such
  criteria are useful for risk management, and are important in domains such as finance
  and process control. We propose variants of both TD(0) and LSTD(Î») with linear function
  approximation, prove their convergence, and demonstrate their utility in a 4-dimensional
  continuous state space problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: tamar13
month: 0
tex_title: Temporal Difference Methods for the Variance of the Reward To Go
firstpage: 495
lastpage: 503
page: 495-503
order: 495
cycles: false
author:
- given: Aviv
  family: Tamar
- given: Dotan
  family: Di Castro
- given: Shie
  family: Mannor
date: 2013-05-26
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 5
  - 26
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
