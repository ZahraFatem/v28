---
pdf: http://proceedings.mlr.press/v28/telgarsky13.pdf
supplementary: Supplementary:telgarsky13-supp.pdf
number: 2
section: cycle-2
title: Margins, Shrinkage, and Boosting
abstract: 'This manuscript shows that AdaBoost and its immediate variants can produce
  approximately maximum margin classifiers simply by scaling their step size choices
  by a fixed small constant. In this way, when the unscaled step size is an optimal
  choice, these results provide guarantees for Friedman’s empirically successful “shrinkage”
  procedure for gradient boosting (Friedman, 2000).  Guarantees are also provided
  for a variety of other step sizes, affirming the intuition that increasingly regularized
  line searches provide improved margin guarantees. The results hold for the exponential
  loss and similar losses, most notably the logistic loss.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: telgarsky13
month: 0
tex_title: Margins, Shrinkage, and Boosting
firstpage: 307
lastpage: 315
page: 307-315
order: 307
cycles: false
author:
- given: Matus
  family: Telgarsky
date: 2013-05-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 5
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
