---
pdf: http://proceedings.mlr.press/v28/kraehenbuehl13.pdf
number: 3
section: cycle-3
title: Parameter Learning and Convergent Inference for Dense Random Fields
abstract: Dense random fields are models in which all pairs of variables are directly
  connected by pairwise potentials. It has recently been shown that mean field inference
  in dense random fields can be performed efficiently and that these models enable
  significant accuracy gains in computer vision applications. However, parameter estimation
  for dense random fields is still poorly understood. In this paper, we present an
  efficient algorithm for learning parameters in dense random fields. All parameters
  are estimated jointly, thus capturing dependencies between them. We show that gradients
  of a variety of loss functions over the mean field marginals can be computed efficiently.
  The resulting algorithm learns parameters that directly optimize the performance
  of mean field inference in the model.  As a supporting result, we present an efficient
  inference algorithm for dense random fields that is guaranteed to converge.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kraehenbuehl13
month: 0
tex_title: Parameter Learning and Convergent Inference for Dense Random Fields
firstpage: 513
lastpage: 521
page: 513-521
order: 513
cycles: false
author:
- given: Philipp
  family: Kraehenbuehl
- given: Vladlen
  family: Koltun
date: 2013-05-26
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 5
  - 26
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
