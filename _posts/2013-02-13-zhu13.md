---
pdf: http://proceedings.mlr.press/v28/zhu13.pdf
title: Gibbs Max-Margin Topic Models with Fast Sampling Algorithms
number: '1'
section: cycle-1
abstract: Existing max-margin supervised topic models rely on an iterative procedure
  to solve multiple latent SVM subproblems with additional mean-field assumptions
  on the desired posterior distributions. This paper presents Gibbs max-margin supervised
  topic models by minimizing an expected margin loss, an upper bound of the existing
  margin loss derived from an expected prediction rule. By introducing augmented variables,
  we develop simple and fast Gibbs sampling algorithms with no restricting assumptions
  and no need to solve SVM subproblems for both classification and regression. Empirical
  results demonstrate significant improvements on time efficiency. The classification
  performance is also significantly improved over competitors.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhu13
month: 0
tex_title: "{G}ibbs Max-Margin Topic Models with Fast Sampling Algorithms"
firstpage: 124
lastpage: 132
page: 124-132
sections: 
author:
- given: Jun
  family: Zhu
- given: Ning
  family: Chen
- given: Hugh
  family: Perkins
- given: Bo
  family: Zhang
date: 2013-02-13
address: Atlanta, Georgia, USA
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Machine Learning
volume: '28'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 2
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
